<div id='div_diffusion_papers_list' class='list-papers'>
    <div class='date-papers'>
        <h2><b>2024-06-10</b></h2>
        <p><a href='https://arxiv.org/abs/2406.01900' target='_blank'>follow-your-emoji: fine-controllable and
                expressive freestyle portrait animation</a><br>
            yue ma, hongyu liu, hongfa wang, heng pan, yingqing he, junkun yuan, ailing zeng, chengfei cai, heung-yeung
            shum, wei liu, qifeng chen
        </p>
        <p><a href='https://arxiv.org/abs/2406.03744' target='_blank'>redistill: residual encoded distillation for peak
                memory reduction</a><br>
            fang chen, gourav datta, mujahid al rafi, hyeran jeon, meng tang
        </p>
        <p><a href='https://arxiv.org/abs/2406.04322' target='_blank'>direct-3d: learning direct text-to-3d generation
                on massive noisy 3d data</a><br>
            qihao liu, yi zhang, song bai, adam kortylewski, alan yuille
        </p>
        <p><a href='https://arxiv.org/abs/2406.04338' target='_blank'>physics3d: learning physical properties of 3d
                gaussians via video diffusion</a><br>
            fangfu liu, hanyang wang, shunyu yao, shengjun zhang, jie zhou, yueqi duan
        </p>
        <p><a href='https://arxiv.org/abs/2406.04542' target='_blank'>m&m vto: multi-garment virtual try-on and
                editing</a><br>
            luyang zhu, yingwei li, nan liu, hao peng, dawei yang, ira kemelmacher-shlizerman
        </p>
        <p><a href='https://arxiv.org/abs/2406.04551' target='_blank'>improving geo-diversity of generated images with
                contextualized vendi score guidance</a><br>
            reyhane askari hemmat, melissa hall, alicia sun, candace ross, michal drozdzal, adriana romero-soriano
        </p>
        <p><a href='https://arxiv.org/abs/2406.04629' target='_blank'>star: skeleton-aware text-based 4d avatar
                generation with in-network motion retargeting</a><br>
            zenghao chai, chen tang, yongkang wong, mohan kankanhalli
        </p>
        <p><a href='https://arxiv.org/abs/2406.04662' target='_blank'>evaluating and mitigating ip infringement in
                visual generative ai</a><br>
            zhenting wang, chen chen, vikash sehwag, minzhou pan, lingjuan lyu
        </p>
        <p><a href='https://arxiv.org/abs/2406.04673' target='_blank'>melfusion: synthesizing music from image and
                language cues using diffusion models</a><br>
            sanjoy chowdhury, sayan nag, k j joseph, balaji vasan srinivasan, dinesh manocha
        </p>
        <p><a href='https://arxiv.org/abs/2406.04746' target='_blank'>pqpp: a joint benchmark for text-to-image prompt
                and query performance prediction</a><br>
            eduard poesina, adriana valentina costache, adrian-gabriel chifu, josiane mothe, radu tudor ionescu
        </p>
        <p><a href='https://arxiv.org/abs/2406.04769' target='_blank'>diffusion-based generative image outpainting for
                recovery of fov-truncated ct images</a><br>
            michelle espranita liman, daniel rueckert, florian j. fintelmann, philip müller
        </p>
        <p><a href='https://arxiv.org/abs/2406.04814' target='_blank'>online continual learning of video diffusion
                models from a single video stream</a><br>
            jason yoo, dylan green, geoff pleiss, frank wood
        </p>
        <p><a href='https://arxiv.org/abs/2406.04983' target='_blank'>citycraft: a real crafter for 3d city
                generation</a><br>
            jie deng, wenhao chai, junsheng huang, zhonghan zhao, qixuan huang, mingyan gao, jianshu guo, shengyu hao,
            wenhao hu, jenq-neng hwang, xi li, gaoang wang
        </p>
        <p><a href='https://arxiv.org/abs/2406.05038' target='_blank'>efficient 3d shape generation via diffusion mamba
                with bidirectional ssms</a><br>
            shentong mo
        </p>
        <p><a href='https://arxiv.org/abs/2406.05059' target='_blank'>genheld: generating and editing handheld
                objects</a><br>
            chaerin min, srinath sridhar
        </p>
        <p><a href='https://arxiv.org/abs/2406.05082' target='_blank'>cono: consistency noise injection for tuning-free
                long video diffusion</a><br>
            xingrui wang, xin li, zhibo chen
        </p>
        <p><a href='https://arxiv.org/abs/2406.05131' target='_blank'>dvos: self-supervised dense-pattern video object
                segmentation</a><br>
            keyhan najafian, farhad maleki, ian stavness, lingling jin
        </p>

    </div>
    <div class='date-papers'>
        <h2><b>2024-06-07</b></h2>
        <p><a href='https://arxiv.org/abs/2406.00773' target='_blank'>diffusion tuning: transferring diffusion models
                via chain of forgetting</a><br>
            jincheng zhong, xingzhuo guo, jiaxiang dong, mingsheng long
        </p>
        <p><a href='https://arxiv.org/abs/2406.01349' target='_blank'>unleashing generalization of end-to-end autonomous
                driving with controllable long video generation</a><br>
            enhui ma, lijun zhou, tao tang, zhan zhang, dong han, junpeng jiang, kun zhan, peng jia, xianpeng lang,
            haiyang sun, di lin, kaicheng yu
        </p>
        <p><a href='https://arxiv.org/abs/2406.02343' target='_blank'>cluster-aware similarity diffusion for instance
                retrieval</a><br>
            jifei luo, hantao yao, changsheng xu
        </p>
        <p><a href='https://arxiv.org/abs/2406.02347' target='_blank'>flash diffusion: accelerating any conditional
                diffusion model for few steps image generation</a><br>
            clement chadebec, onur tasar, eyal benaroche, benjamin aubin
        </p>
        <p><a href='https://arxiv.org/abs/2406.02541' target='_blank'>enhancing temporal consistency in video editing by
                reconstructing videos with 3d gaussian splatting</a><br>
            inkyu shin, qihang yu, xiaohui shen, in so kweon, kuk-jin yoon, liang-chieh chen
        </p>
        <p><a href='https://arxiv.org/abs/2406.02881' target='_blank'>inv-adapter: id customization generation via image
                inversion and lightweight adapter</a><br>
            peng xing, ning wang, jianbo ouyang, zechao li
        </p>
        <p><a href='https://arxiv.org/abs/2406.02918' target='_blank'>u-kan makes strong backbone for medical image
                segmentation and generation</a><br>
            chenxin li, xinyu liu, wuyang li, cheng wang, hengyu liu, yixuan yuan
        </p>
        <p><a href='https://arxiv.org/abs/2406.03582' target='_blank'>understanding the limitations of diffusion concept
                algebra through food</a><br>
            e. zhixuan zeng, yuhao chen, alexander wong
        </p>
        <p><a href='https://arxiv.org/abs/2406.03720' target='_blank'>jigmark: a black-box approach for enhancing image
                watermarks against diffusion model edits</a><br>
            minzhou pan, yi zeng, xue lin, ning yu, cho-jui hsieh, peter henderson, ruoxi jia
        </p>
        <p><a href='https://arxiv.org/abs/2406.03866' target='_blank'>llplace: the 3d indoor scene layout generation and
                editing via large language model</a><br>
            yixuan yang, junru lu, zixiang zhao, zhen luo, james j. q. yu, victor sanchez, feng zheng
        </p>
        <p><a href='https://arxiv.org/abs/2406.03961' target='_blank'>ldm-rsic: exploring distortion prior with latent
                diffusion models for remote sensing image compression</a><br>
            junhui li, jutao li, xingsong hou, huake wang, yutao zhang, yujie dun, wenke sun
        </p>
        <p><a href='https://arxiv.org/abs/2406.04103' target='_blank'>multistep distillation of diffusion models via
                moment matching</a><br>
            tim salimans, thomas mensink, jonathan heek, emiel hoogeboom
        </p>
        <p><a href='https://arxiv.org/abs/2406.04177' target='_blank'>a voxel-based approach for simulating microbial
                decomposition in soil: comparison with lbm and improvement of morphological models</a><br>
            mouad klai, olivier monga, mohamed soufiane jouini, valérie pot
        </p>
        <p><a href='https://arxiv.org/abs/2406.04206' target='_blank'>diffusion-based image inpainting with internal
                learning</a><br>
            nicolas cherel, andrés almansa, yann gousseau, alasdair newson
        </p>
        <p><a href='https://arxiv.org/abs/2406.04253' target='_blank'>a survey on 3d human avatar modeling -- from
                reconstruction to generation</a><br>
            ruihe wang, yukang cao, kai han, kwan-yee k. wong
        </p>
        <p><a href='https://arxiv.org/abs/2406.04277' target='_blank'>videotetris: towards compositional text-to-video
                generation</a><br>
            ye tian, ling yang, haotian yang, yuan gao, yufan deng, jingmin chen, xintao wang, zhaochen yu, xin tao,
            pengfei wan, di zhang, bin cui
        </p>
        <p><a href='https://arxiv.org/abs/2406.04295' target='_blank'>everything to the synthetic: diffusion-driven
                test-time adaptation via synthetic-domain alignment</a><br>
            jiayi guo, junhao zhao, chunjiang ge, chaoqun du, zanlin ni, shiji song, humphrey shi, gao huang
        </p>
        <p><a href='https://arxiv.org/abs/2406.04312' target='_blank'>reno: enhancing one-step text-to-image models
                through reward-based noise optimization</a><br>
            luca eyring, shyamgopal karthik, karsten roth, alexey dosovitskiy, zeynep akata
        </p>
        <p><a href='https://arxiv.org/abs/2406.04314' target='_blank'>step-aware preference optimization: aligning
                preference with denoising performance at each step</a><br>
            zhanhao liang, yuhui yuan, shuyang gu, bohan chen, tiankai hang, ji li, liang zheng
        </p>
        <p><a href='https://arxiv.org/abs/2406.04323' target='_blank'>atradiff: accelerating online reinforcement
                learning with imaginary trajectories</a><br>
            qianlan yang, yu-xiong wang
        </p>
        <p><a href='https://arxiv.org/abs/2406.04324' target='_blank'>sf-v: single forward video generation
                model</a><br>
            zhixing zhang, yanyu li, yushu wu, yanwu xu, anil kag, ivan skorokhodov, willi menapace, aliaksandr
            siarohin, junli cao, dimitris metaxas, sergey tulyakov, jian ren
        </p>
        <p><a href='https://arxiv.org/abs/2406.04333' target='_blank'>bitsfusion: 1.99 bits weight quantization of
                diffusion model</a><br>
            yang sui, yanyu li, anil kag, yerlan idelbayev, junli cao, ju hu, dhritiman sagar, bo yuan, sergey tulyakov,
            jian ren
        </p>
        <p><a href='https://arxiv.org/abs/2406.04337' target='_blank'>coherent zero-shot visual instruction
                generation</a><br>
            quynh phung, songwei ge, jia-bin huang
        </p>
        <p><a href='https://arxiv.org/abs/2406.04340' target='_blank'>glace: global local accelerated coordinate
                encoding</a><br>
            fangjinhua wang, xudong jiang, silvano galliani, christoph vogel, marc pollefeys
        </p>

    </div>


    <div class='date-papers'>
        <h2><b>2024-06-06</b></h2>
        <p><a href='https://arxiv.org/abs/2406.01136' target='_blank'>towards practical single-shot motion
                synthesis</a><br>
            konstantinos roditakis, spyridon thermos, nikolaos zioulis
        </p>
        <p><a href='https://arxiv.org/abs/2406.02653' target='_blank'>pancreatic tumor segmentation as anomaly detection
                in ct images using denoising diffusion models</a><br>
            reza babaei, samuel cheng, theresa thai, shangqing zhao
        </p>
        <p><a href='https://arxiv.org/abs/2406.02659' target='_blank'>neural representations of dynamic visual
                stimuli</a><br>
            jacob yeung, andrew f. luo, gabriel sarch, margaret m. henderson, deva ramanan, michael j. tarr
        </p>
        <p><a href='https://arxiv.org/abs/2406.02774' target='_blank'>diffusion-refined vqa annotations for
                semi-supervised gaze following</a><br>
            qiaomu miao, alexandros graikos, jingwei zhang, sounak mondal, minh hoai, dimitris samaras
        </p>
        <p><a href='https://arxiv.org/abs/2406.02820' target='_blank'>oracle: leveraging mutual information for
                consistent character generation with loras in diffusion models</a><br>
            kiymet akdemir, pinar yanardag
        </p>
        <p><a href='https://arxiv.org/abs/2406.02842' target='_blank'>zero-shot image segmentation via recursive
                normalized cut on diffusion features</a><br>
            paul couairon, mustafa shukor, jean-emmanuel haugeard, matthieu cord, nicolas thome
        </p>
        <p><a href='https://arxiv.org/abs/2406.02929' target='_blank'>exploring data efficiency in zero-shot learning
                with diffusion models</a><br>
            zihan ye, shreyank n. gowda, xiaobo jin, xiaowei huang, haotian xu, yaochu jin, kaizhu huang
        </p>
        <p><a href='https://arxiv.org/abs/2406.02936' target='_blank'>radiomics-guided multimodal self-attention network
                for predicting pathological complete response in breast mri</a><br>
            jonghun kim, hyunjin park
        </p>
        <p><a href='https://arxiv.org/abs/2406.02965' target='_blank'>understanding the impact of negative prompts: when
                and how do they take effect?</a><br>
            yuanhao ban, ruochen wang, tianyi zhou, minhao cheng, boqing gong, cho-jui hsieh
        </p>
        <p><a href='https://arxiv.org/abs/2406.03002' target='_blank'>phy-diff: physics-guided hourglass diffusion model
                for diffusion mri synthesis</a><br>
            juanhua zhang, ruodan yan, alessandro perelli, xi chen, chao li
        </p>
        <p><a href='https://arxiv.org/abs/2406.03129' target='_blank'>enhanced automotive object detection via rgb-d
                fusion in a diffusiondet framework</a><br>
            eliraz orfaig, inna stainvas, igal bilik
        </p>
        <p><a href='https://arxiv.org/abs/2406.03146' target='_blank'>tiny models from tiny data: textual and null-text
                inversion for few-shot distillation</a><br>
            erik landolsi, fredrik kahl
        </p>
        <p><a href='https://arxiv.org/abs/2406.03184' target='_blank'>ouroboros3d: image-to-3d generation via 3d-aware
                recursive diffusion</a><br>
            hao wen, zehuan huang, yaohui wang, xinyuan chen, yu qiao, lu sheng
        </p>
        <p><a href='https://arxiv.org/abs/2406.03215' target='_blank'>searching priors makes text-to-video synthesis
                better</a><br>
            haoran cheng, liang peng, linxuan xia, yuepeng hu, hengjia li, qinglin lu, xiaofei he, boxi wu
        </p>
        <p><a href='https://arxiv.org/abs/2406.03233' target='_blank'>generative diffusion models for fast simulations
                of particle collisions at cern</a><br>
            mikołaj kita, jan dubiński, przemysław rokita, kamil deja
        </p>
        <p><a href='https://arxiv.org/abs/2406.03293' target='_blank'>text-to-image rectified flow as plug-and-play
                priors</a><br>
            xiaofeng yang, cheng chen, xulei yang, fayao liu, guosheng lin
        </p>
        <p><a href='https://arxiv.org/abs/2406.03439' target='_blank'>text-to-events: synthetic event camera streams
                from conditional text input</a><br>
            joachim ott, zuowen wang, shih-chii liu
        </p>

    </div>

</div>