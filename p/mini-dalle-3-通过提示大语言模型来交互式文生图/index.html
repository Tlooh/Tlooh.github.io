<!DOCTYPE html>
<html lang="en" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content="Mini DALL·E 3: Interactive Text to Image by Prompting Large Language Models 介绍 Mini DALL·E 3 是一个基于大型语言模型的交互式文本到图像的生成系统。 用户可以通过自然语言指令请求生成图像，并能在不满意时进行编辑请求,系统能在多轮对话中识别上下文并作出相应调整。 从介绍图来看，确实是一个比较新颖的点，所以记录下这篇文章具体怎么做的 这是一个图像生成方式的演变，作者这里想说明的是这种交互式编辑，或者是多模态大模型在是未来的演变方向； 主要是因为目前的SD主流生成语言是与人类自然语言不符合的，其实在 C站上也看的出来，很多精致的基模或者画风，他们的prompt都是以关键词给出的，并非人类描述的自然语句； 交互式图像生成 问题定义 这种交互式的图像生成有三个点需要注意的： 多轮交互 指系统与用户进行动态和迭代对话的能力。多回合iT2I系统可以接受多轮文本输入，使用户能够通过正在进行的对话来改进和指定他们的视觉需求。此属性增强了用户体验，并允许对生成的图像进行更细粒度的控制。 一致性 意味着系统可以自动确定是否不仅要考虑当前的文本输入，还要考虑之前的视觉上下文。它包括在上下文中保持图像的视觉特性。这种能力使iT2I系统能够执行一致的多回合图像编辑/改进，产生个性化和上下文相关的对象/角色等。 可组合性 与将图像生成与其他任务结合或集成的能力有关。这意味着图像生成的能力应该是模块化的，并与llm的固有能力兼容，允许用户无缝地将它们合并在一起，以执行查询文本和视觉内容的交错保存。 指令类型 如下图所示，在iT2I系统中有生成、编辑、选择和细化等。不同的指令可能有不同的复杂程度。一些指令可以通过利用LLM的功能来有效地处理；某些指令可能需要LLM和T2I模型之间更深层次的协同作用。 生成指的是，iT2I系统从零开始创建图像或插图，试图捕捉所提供文本输入的本质和细节。它本质上是将查询转换为T2I模型的神经表示或提示。 参考生成是生成的另一种变体，系统参考由文本输入中提到的现有对象、场景或概念所激发的图像，或者出现在上下文中图像进行生成; 选择是一个相对简单的指令，它涉及根据文本输入从一组预先存在的或生成的图像中进行选择。 编辑执行的任务是修改或完善现有的图像，以响应文本指令。这可能涉及改变图像的特定属性，增强或减少某些特征，或调整图像以匹配指令中概述的要求。 细化意味着进一步增强或优化现有图像，以更好地与文本描述保持一致，以达到更高水平的细节，现实主义，或与提供的文本指导相一致的准确性。 回答问题是LLM与生俱来的能力。为用户提供交错的图像和文本的连贯体验是至关重要的。 Mini-DALLE3 Mini-DALLE3的整体架构如下图所示，它包括几个关键组件:LLM、路由器、适配器和T2I模型。 LLM可以是现有的纯文本LLM，如ChatGPT和LLaMA，也可以是VisionLLM。它负责分析用户意图，并以文本或神经网络表示产生适当的输出。 Router 会自动调度解析后的图像表示(如果LLM输出中存在)分发给图像生成模块。 Adapter 转换图像表示，以更好地适应后端T2I模型。 基于 LLM 提示的多轮交互 多回合交互是交互式文本到图像的核心。它需要整合文本/视觉上下文语境信息和指令而非描述性信息。 为了解决这个问题，作者通过文本描述来 prompting LLM ,从而伪装生成图像来利用LLM更强的上下文理解能力。 这种中间文本描述不仅提供了更强的灵活性，可以通过即插即用模块（如快速变化/改进）增强系统功能，而且使我们能够利用大量预训练的LLM和T2I模型，而无需进行大量微调； 图像生成作为函数调用 具体来说，我们利用如图5所示的小样本提示，将多轮图像生成问题转化为多轮文本描述生成问题。 首先，我们定义语言模型（LM）的角色，并明确地向它传达它有能力生成图像。 随后，我们要求语言模型通过生成包含在⟨image⟩标签内的描述性文本来产生图像。 如果生成的图像与之前的图像高度相关，选择“编辑”而非重新“生成”图像 最后，我们提供了一些小样本示例，以进一步指导语言模型的响应。 提示细化和变体 通过提示大型语言模型（LLMs）来生成融合了上下文信息的文本描述，可能不足以生成高质量的图像。因此，作者利用提示细化，将普通的描述转化为更适合后续文本到图像（T2I）模型的描述。 如果之前的中间表示是embedding的，那么提示细化也可以应用于embedding。作者还是利用通过使用few-shot prompt再次提示LLM来执行文本转换。（可以通过反复执行不同的提示细化来进行提示变体） 分级内容一致性控制 把工作能力（subject-driven T2I, example-driven T2I, personalization, concept learning）整合到一个统一的系统中。分层控制策略，指针对不同级别的内容变化使用不同的模型。">
<title>Mini DALL·E 3: 通过提示大语言模型来交互式文生图</title>

<link rel='canonical' href='https://tlooh.github.io/p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/'>

<link rel="stylesheet" href="/scss/style.min.add8fb3bab9b743b892af012a73b6880459349cb1f020823ea8cdafee6e03d6d.css"><meta property='og:title' content="Mini DALL·E 3: 通过提示大语言模型来交互式文生图">
<meta property='og:description' content="Mini DALL·E 3: Interactive Text to Image by Prompting Large Language Models 介绍 Mini DALL·E 3 是一个基于大型语言模型的交互式文本到图像的生成系统。 用户可以通过自然语言指令请求生成图像，并能在不满意时进行编辑请求,系统能在多轮对话中识别上下文并作出相应调整。 从介绍图来看，确实是一个比较新颖的点，所以记录下这篇文章具体怎么做的 这是一个图像生成方式的演变，作者这里想说明的是这种交互式编辑，或者是多模态大模型在是未来的演变方向； 主要是因为目前的SD主流生成语言是与人类自然语言不符合的，其实在 C站上也看的出来，很多精致的基模或者画风，他们的prompt都是以关键词给出的，并非人类描述的自然语句； 交互式图像生成 问题定义 这种交互式的图像生成有三个点需要注意的： 多轮交互 指系统与用户进行动态和迭代对话的能力。多回合iT2I系统可以接受多轮文本输入，使用户能够通过正在进行的对话来改进和指定他们的视觉需求。此属性增强了用户体验，并允许对生成的图像进行更细粒度的控制。 一致性 意味着系统可以自动确定是否不仅要考虑当前的文本输入，还要考虑之前的视觉上下文。它包括在上下文中保持图像的视觉特性。这种能力使iT2I系统能够执行一致的多回合图像编辑/改进，产生个性化和上下文相关的对象/角色等。 可组合性 与将图像生成与其他任务结合或集成的能力有关。这意味着图像生成的能力应该是模块化的，并与llm的固有能力兼容，允许用户无缝地将它们合并在一起，以执行查询文本和视觉内容的交错保存。 指令类型 如下图所示，在iT2I系统中有生成、编辑、选择和细化等。不同的指令可能有不同的复杂程度。一些指令可以通过利用LLM的功能来有效地处理；某些指令可能需要LLM和T2I模型之间更深层次的协同作用。 生成指的是，iT2I系统从零开始创建图像或插图，试图捕捉所提供文本输入的本质和细节。它本质上是将查询转换为T2I模型的神经表示或提示。 参考生成是生成的另一种变体，系统参考由文本输入中提到的现有对象、场景或概念所激发的图像，或者出现在上下文中图像进行生成; 选择是一个相对简单的指令，它涉及根据文本输入从一组预先存在的或生成的图像中进行选择。 编辑执行的任务是修改或完善现有的图像，以响应文本指令。这可能涉及改变图像的特定属性，增强或减少某些特征，或调整图像以匹配指令中概述的要求。 细化意味着进一步增强或优化现有图像，以更好地与文本描述保持一致，以达到更高水平的细节，现实主义，或与提供的文本指导相一致的准确性。 回答问题是LLM与生俱来的能力。为用户提供交错的图像和文本的连贯体验是至关重要的。 Mini-DALLE3 Mini-DALLE3的整体架构如下图所示，它包括几个关键组件:LLM、路由器、适配器和T2I模型。 LLM可以是现有的纯文本LLM，如ChatGPT和LLaMA，也可以是VisionLLM。它负责分析用户意图，并以文本或神经网络表示产生适当的输出。 Router 会自动调度解析后的图像表示(如果LLM输出中存在)分发给图像生成模块。 Adapter 转换图像表示，以更好地适应后端T2I模型。 基于 LLM 提示的多轮交互 多回合交互是交互式文本到图像的核心。它需要整合文本/视觉上下文语境信息和指令而非描述性信息。 为了解决这个问题，作者通过文本描述来 prompting LLM ,从而伪装生成图像来利用LLM更强的上下文理解能力。 这种中间文本描述不仅提供了更强的灵活性，可以通过即插即用模块（如快速变化/改进）增强系统功能，而且使我们能够利用大量预训练的LLM和T2I模型，而无需进行大量微调； 图像生成作为函数调用 具体来说，我们利用如图5所示的小样本提示，将多轮图像生成问题转化为多轮文本描述生成问题。 首先，我们定义语言模型（LM）的角色，并明确地向它传达它有能力生成图像。 随后，我们要求语言模型通过生成包含在⟨image⟩标签内的描述性文本来产生图像。 如果生成的图像与之前的图像高度相关，选择“编辑”而非重新“生成”图像 最后，我们提供了一些小样本示例，以进一步指导语言模型的响应。 提示细化和变体 通过提示大型语言模型（LLMs）来生成融合了上下文信息的文本描述，可能不足以生成高质量的图像。因此，作者利用提示细化，将普通的描述转化为更适合后续文本到图像（T2I）模型的描述。 如果之前的中间表示是embedding的，那么提示细化也可以应用于embedding。作者还是利用通过使用few-shot prompt再次提示LLM来执行文本转换。（可以通过反复执行不同的提示细化来进行提示变体） 分级内容一致性控制 把工作能力（subject-driven T2I, example-driven T2I, personalization, concept learning）整合到一个统一的系统中。分层控制策略，指针对不同级别的内容变化使用不同的模型。">
<meta property='og:url' content='https://tlooh.github.io/p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/'>
<meta property='og:site_name' content='Tlooh Blog Site'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:tag' content='交互式文生图' /><meta property='article:published_time' content='2024-08-10T01:12:44&#43;08:00'/><meta property='article:modified_time' content='2024-08-20T22:34:15&#43;08:00'/><meta property='og:image' content='https://tlooh.github.io/p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-4.png' />
<meta name="twitter:title" content="Mini DALL·E 3: 通过提示大语言模型来交互式文生图">
<meta name="twitter:description" content="Mini DALL·E 3: Interactive Text to Image by Prompting Large Language Models 介绍 Mini DALL·E 3 是一个基于大型语言模型的交互式文本到图像的生成系统。 用户可以通过自然语言指令请求生成图像，并能在不满意时进行编辑请求,系统能在多轮对话中识别上下文并作出相应调整。 从介绍图来看，确实是一个比较新颖的点，所以记录下这篇文章具体怎么做的 这是一个图像生成方式的演变，作者这里想说明的是这种交互式编辑，或者是多模态大模型在是未来的演变方向； 主要是因为目前的SD主流生成语言是与人类自然语言不符合的，其实在 C站上也看的出来，很多精致的基模或者画风，他们的prompt都是以关键词给出的，并非人类描述的自然语句； 交互式图像生成 问题定义 这种交互式的图像生成有三个点需要注意的： 多轮交互 指系统与用户进行动态和迭代对话的能力。多回合iT2I系统可以接受多轮文本输入，使用户能够通过正在进行的对话来改进和指定他们的视觉需求。此属性增强了用户体验，并允许对生成的图像进行更细粒度的控制。 一致性 意味着系统可以自动确定是否不仅要考虑当前的文本输入，还要考虑之前的视觉上下文。它包括在上下文中保持图像的视觉特性。这种能力使iT2I系统能够执行一致的多回合图像编辑/改进，产生个性化和上下文相关的对象/角色等。 可组合性 与将图像生成与其他任务结合或集成的能力有关。这意味着图像生成的能力应该是模块化的，并与llm的固有能力兼容，允许用户无缝地将它们合并在一起，以执行查询文本和视觉内容的交错保存。 指令类型 如下图所示，在iT2I系统中有生成、编辑、选择和细化等。不同的指令可能有不同的复杂程度。一些指令可以通过利用LLM的功能来有效地处理；某些指令可能需要LLM和T2I模型之间更深层次的协同作用。 生成指的是，iT2I系统从零开始创建图像或插图，试图捕捉所提供文本输入的本质和细节。它本质上是将查询转换为T2I模型的神经表示或提示。 参考生成是生成的另一种变体，系统参考由文本输入中提到的现有对象、场景或概念所激发的图像，或者出现在上下文中图像进行生成; 选择是一个相对简单的指令，它涉及根据文本输入从一组预先存在的或生成的图像中进行选择。 编辑执行的任务是修改或完善现有的图像，以响应文本指令。这可能涉及改变图像的特定属性，增强或减少某些特征，或调整图像以匹配指令中概述的要求。 细化意味着进一步增强或优化现有图像，以更好地与文本描述保持一致，以达到更高水平的细节，现实主义，或与提供的文本指导相一致的准确性。 回答问题是LLM与生俱来的能力。为用户提供交错的图像和文本的连贯体验是至关重要的。 Mini-DALLE3 Mini-DALLE3的整体架构如下图所示，它包括几个关键组件:LLM、路由器、适配器和T2I模型。 LLM可以是现有的纯文本LLM，如ChatGPT和LLaMA，也可以是VisionLLM。它负责分析用户意图，并以文本或神经网络表示产生适当的输出。 Router 会自动调度解析后的图像表示(如果LLM输出中存在)分发给图像生成模块。 Adapter 转换图像表示，以更好地适应后端T2I模型。 基于 LLM 提示的多轮交互 多回合交互是交互式文本到图像的核心。它需要整合文本/视觉上下文语境信息和指令而非描述性信息。 为了解决这个问题，作者通过文本描述来 prompting LLM ,从而伪装生成图像来利用LLM更强的上下文理解能力。 这种中间文本描述不仅提供了更强的灵活性，可以通过即插即用模块（如快速变化/改进）增强系统功能，而且使我们能够利用大量预训练的LLM和T2I模型，而无需进行大量微调； 图像生成作为函数调用 具体来说，我们利用如图5所示的小样本提示，将多轮图像生成问题转化为多轮文本描述生成问题。 首先，我们定义语言模型（LM）的角色，并明确地向它传达它有能力生成图像。 随后，我们要求语言模型通过生成包含在⟨image⟩标签内的描述性文本来产生图像。 如果生成的图像与之前的图像高度相关，选择“编辑”而非重新“生成”图像 最后，我们提供了一些小样本示例，以进一步指导语言模型的响应。 提示细化和变体 通过提示大型语言模型（LLMs）来生成融合了上下文信息的文本描述，可能不足以生成高质量的图像。因此，作者利用提示细化，将普通的描述转化为更适合后续文本到图像（T2I）模型的描述。 如果之前的中间表示是embedding的，那么提示细化也可以应用于embedding。作者还是利用通过使用few-shot prompt再次提示LLM来执行文本转换。（可以通过反复执行不同的提示细化来进行提示变体） 分级内容一致性控制 把工作能力（subject-driven T2I, example-driven T2I, personalization, concept learning）整合到一个统一的系统中。分层控制策略，指针对不同级别的内容变化使用不同的模型。"><meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content='https://tlooh.github.io/p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-4.png' />
  


    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended">



        <div id="article-toolbar" style="position: sticky;top: 5px;z-index: 1000;">
            <a href="/" class="back-home">
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-chevron-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="15 6 9 12 15 18" />
</svg>



                <span>Back</span>
            </a>
        </div>
    

    <aside class="sidebar right-sidebar sticky">
        
            
                
    <section class="widget archives">
        <div class="widget-icon">
            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <line x1="5" y1="9" x2="19" y2="9" />
  <line x1="5" y1="15" x2="19" y2="15" />
  <line x1="11" y1="4" x2="7" y2="20" />
  <line x1="17" y1="4" x2="13" y2="20" />
</svg>



        </div>
        <h2 class="widget-title section-title">Table of contents</h2>
        
        <div class="widget--toc">
            <nav id="TableOfContents">
  <ol>
    <li><a href="#介绍">介绍</a></li>
    <li><a href="#交互式图像生成">交互式图像生成</a>
      <ol>
        <li><a href="#问题定义">问题定义</a>
          <ol>
            <li><a href="#多轮交互">多轮交互</a></li>
            <li><a href="#一致性">一致性</a></li>
            <li><a href="#可组合性">可组合性</a></li>
          </ol>
        </li>
        <li><a href="#指令类型">指令类型</a></li>
      </ol>
    </li>
    <li><a href="#mini-dalle3">Mini-DALLE3</a>
      <ol>
        <li><a href="#基于-llm-提示的多轮交互">基于 LLM 提示的多轮交互</a>
          <ol>
            <li><a href="#图像生成作为函数调用">图像生成作为函数调用</a></li>
            <li><a href="#提示细化和变体">提示细化和变体</a></li>
          </ol>
        </li>
        <li><a href="#分级内容一致性控制">分级内容一致性控制</a></li>
      </ol>
    </li>
    <li><a href="#实验">实验</a></li>
  </ol>
</nav>
        </div>
    </section>

            
        
    </aside>


            <main class="main full-width">
    <article class="has-image main-article">
    <header class="article-header">
        <div class="article-image">
            <a href="/p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/">
                <img src="/p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-4_huc82d7b839fc53b7a5c86bd3cdfedcac6_308256_800x0_resize_box_3.png"
                        srcset="/p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-4_huc82d7b839fc53b7a5c86bd3cdfedcac6_308256_800x0_resize_box_3.png 800w, /p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-4_huc82d7b839fc53b7a5c86bd3cdfedcac6_308256_1600x0_resize_box_3.png 1600w"
                        width="800" 
                        height="585" 
                        loading="lazy"
                        alt="Featured image of post Mini DALL·E 3: 通过提示大语言模型来交互式文生图" />
                
            </a>
        </div>
    

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/diffusion/" >
                Diffusion
            </a>
        
            <a href="/categories/llm/" >
                LLM
            </a>
        
            <a href="/categories/papers/" >
                Papers
            </a>
        
    </header>
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/">Mini DALL·E 3: 通过提示大语言模型来交互式文生图</a>
        </h2>
    
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">Aug 10, 2024</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    1 minute read
                </time>
            </div>
        
    </footer>
    

    
</div>

</header>

    <section class="article-content">
    
    
    <h1 id="mini-dalle-3-interactive-text-to-image-by-prompting-large-language-models">Mini DALL·E 3: Interactive Text to Image by Prompting Large Language Models
</h1><hr>
<p><img src="/p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image.png"
	width="1606"
	height="846"
	srcset="/p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image_huc82d7b839fc53b7a5c86bd3cdfedcac6_987907_480x0_resize_box_3.png 480w, /p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image_huc82d7b839fc53b7a5c86bd3cdfedcac6_987907_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="Alt text"
	
	
		class="gallery-image" 
		data-flex-grow="189"
		data-flex-basis="455px"
	
></p>
<h2 id="介绍">介绍
</h2><ul>
<li>Mini DALL·E 3 是一个基于大型语言模型的<strong>交互式文本到图像</strong>的生成系统。</li>
<li>用户可以通过自然语言指令请求生成图像，<strong>并能在不满意时进行编辑请求</strong>,系统能在多轮对话中识别上下文并作出相应调整。</li>
</ul>
<p>从介绍图来看，确实是一个比较新颖的点，所以记录下这篇文章具体怎么做的</p>
<p>这是一个图像生成方式的演变，作者这里想说明的是这种交互式编辑，或者是多模态大模型在是未来的演变方向；</p>
<p><img src="/p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-1.png"
	width="1098"
	height="850"
	srcset="/p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-1_huc82d7b839fc53b7a5c86bd3cdfedcac6_459446_480x0_resize_box_3.png 480w, /p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-1_huc82d7b839fc53b7a5c86bd3cdfedcac6_459446_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="Alt text"
	
	
		class="gallery-image" 
		data-flex-grow="129"
		data-flex-basis="310px"
	
></p>
<p>主要是因为目前的SD主流生成语言是与人类自然语言不符合的，其实在 C站上也看的出来，很多精致的基模或者画风，他们的prompt都是以关键词给出的，并非人类描述的自然语句；</p>
<p><img src="/p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-2.png"
	width="2076"
	height="718"
	srcset="/p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-2_huc82d7b839fc53b7a5c86bd3cdfedcac6_617179_480x0_resize_box_3.png 480w, /p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-2_huc82d7b839fc53b7a5c86bd3cdfedcac6_617179_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="Alt text"
	
	
		class="gallery-image" 
		data-flex-grow="289"
		data-flex-basis="693px"
	
></p>
<h2 id="交互式图像生成">交互式图像生成
</h2><h3 id="问题定义">问题定义
</h3><p>这种交互式的图像生成有三个点需要注意的：</p>
<h4 id="多轮交互">多轮交互
</h4><p>指系统与用户进行动态和迭代对话的能力。多回合<code>iT2I</code>系统可以接受多轮文本输入，使用户能够通过正在进行的对话来改进和指定他们的视觉需求。此属性增强了用户体验，并允许对生成的图像进行更细粒度的控制。</p>
<h4 id="一致性">一致性
</h4><p>意味着系统可以自动确定是否不仅要考虑当前的文本输入，还要考虑之前的视觉上下文。它包括在上下文中保持图像的视觉特性。这种能力使iT2I系统能够执行一致的多回合图像编辑/改进，产生个性化和上下文相关的对象/角色等。</p>
<h4 id="可组合性">可组合性
</h4><p>与将图像生成与其他任务结合或集成的能力有关。<strong>这意味着图像生成的能力应该是模块化的</strong>，并与llm的固有能力兼容，允许用户无缝地将它们合并在一起，以执行查询文本和视觉内容的交错保存。</p>
<h3 id="指令类型">指令类型
</h3><p>如下图所示，在iT2I系统中有生成、编辑、选择和细化等。不同的指令可能有不同的复杂程度。一些指令可以通过<strong>利用LLM的功能</strong>来有效地处理；某些指令<strong>可能需要LLM和T2I模型之</strong>间更深层次的协同作用。</p>
<p><img src="/p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-3.png"
	width="2040"
	height="1044"
	srcset="/p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-3_huc82d7b839fc53b7a5c86bd3cdfedcac6_1296114_480x0_resize_box_3.png 480w, /p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-3_huc82d7b839fc53b7a5c86bd3cdfedcac6_1296114_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="Alt text"
	
	
		class="gallery-image" 
		data-flex-grow="195"
		data-flex-basis="468px"
	
></p>
<p><strong>生成</strong>指的是，iT2I系统从零开始创建图像或插图，试图捕捉所提供文本输入的本质和细节。它本质上是将查询转换为T2I模型的神经表示或提示。</p>
<p><strong>参考生成</strong>是生成的另一种变体，系统参考由文本输入中提到的现有对象、场景或概念所激发的图像，或者出现在上下文中图像进行生成;</p>
<p><strong>选择</strong>是一个相对简单的指令，它涉及根据文本输入从一组预先存在的或生成的图像中进行选择。</p>
<p><strong>编辑</strong>执行的任务是修改或完善现有的图像，以响应文本指令。这可能涉及改变图像的特定属性，增强或减少某些特征，或调整图像以匹配指令中概述的要求。</p>
<p><strong>细化</strong>意味着进一步增强或优化现有图像，以更好地与文本描述保持一致，以达到更高水平的细节，现实主义，或与提供的文本指导相一致的准确性。</p>
<p><strong>回答问题</strong>是LLM与生俱来的能力。为用户提供交错的图像和文本的连贯体验是至关重要的。</p>
<h2 id="mini-dalle3">Mini-DALLE3
</h2><p>Mini-DALLE3的整体架构如下图所示，它包括几个关键组件:LLM、路由器、适配器和T2I模型。</p>
<p><img src="/p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-4.png"
	width="1048"
	height="766"
	srcset="/p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-4_huc82d7b839fc53b7a5c86bd3cdfedcac6_308256_480x0_resize_box_3.png 480w, /p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-4_huc82d7b839fc53b7a5c86bd3cdfedcac6_308256_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="Alt text"
	
	
		class="gallery-image" 
		data-flex-grow="136"
		data-flex-basis="328px"
	
></p>
<p>LLM可以是现有的纯文本LLM，如ChatGPT和LLaMA，也可以是VisionLLM。它负责分析用户意图，并以文本或神经网络表示产生适当的输出。</p>
<ul>
<li><code>Router</code> 会自动调度解析后的图像表示(如果LLM输出中存在)分发给图像生成模块。</li>
<li><code>Adapter</code> 转换图像表示，以更好地适应后端T2I模型。</li>
</ul>
<h3 id="基于-llm-提示的多轮交互">基于 LLM 提示的多轮交互
</h3><p>多回合交互是交互式文本到图像的核心。它需要整合文本/视觉上下文语境信息和指令而非描述性信息。</p>
<p>为了解决这个问题，作者通过文本描述来 <code>prompting</code> LLM ,从而伪装生成图像来利用LLM更强的上下文理解能力。</p>
<p>这种中间文本描述不仅提供了更强的灵活性，可以通过即插即用模块（如快速变化/改进）增强系统功能，而且使我们能够利用大量预训练的LLM和T2I模型，而无需进行大量微调；</p>
<h4 id="图像生成作为函数调用">图像生成作为函数调用
</h4><p>具体来说，我们利用如图5所示的小样本提示，<strong>将多轮图像生成问题转化为多轮文本描述生成问题。</strong></p>
<p><img src="/p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-7.png"
	width="1902"
	height="1154"
	srcset="/p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-7_huc82d7b839fc53b7a5c86bd3cdfedcac6_1424439_480x0_resize_box_3.png 480w, /p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-7_huc82d7b839fc53b7a5c86bd3cdfedcac6_1424439_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="Alt text"
	
	
		class="gallery-image" 
		data-flex-grow="164"
		data-flex-basis="395px"
	
></p>
<ul>
<li>首先，我们定义语言模型（LM）的角色，并明确地向它传达它有能力生成图像。</li>
<li>随后，我们要求语言模型通过生成包含在⟨image⟩标签内的描述性文本来产生图像。</li>
<li>如果生成的图像与之前的图像高度相关，选择“编辑”而非重新“生成”图像</li>
<li>最后，我们提供了一些小样本示例，以进一步指导语言模型的响应。</li>
</ul>
<h4 id="提示细化和变体">提示细化和变体
</h4><p><strong>通过提示大型语言模型（LLMs）来生成融合了上下文信息的文本描述，可能不足以生成高质量的图像</strong>。因此，作者利用提示细化，将普通的描述转化为更适合后续文本到图像（T2I）模型的描述。</p>
<p>如果之前的中间表示是embedding的，那么提示细化也可以应用于embedding。作者还是利用通过使用few-shot prompt再次提示LLM来执行文本转换。（可以通过反复执行不同的提示细化来进行提示变体）</p>
<h3 id="分级内容一致性控制">分级内容一致性控制
</h3><p>把工作能力（subject-driven T2I,
example-driven T2I, personalization, concept learning）整合到一个统一的系统中。分层控制策略，指针对不同级别的内容变化使用不同的模型。</p>
<p><strong>具体来说，就是利用现成的Ip-adapter，将先前的图像作为额外的输入，以确保一致的多回合生成。</strong></p>
<ul>
<li>
<p>对于可以用几个词来描述的小的内容变化，如样式的变化、单词权重的变化、简单的对象操作等，我们采用Prompt to Prompt[32]和MasaCtrl[8]模型。</p>
</li>
<li>
<p>我们使用IP-Adapter[60]来执行大的内容更改，因为这些模型对于输入文本提示更灵活。</p>
</li>
</ul>
<h2 id="实验">实验
</h2><p><strong>提示是否会损害LLM的内在能力</strong></p>
<p>我们对MMLU的五个子任务进行了消融研究[19]，比较了有和没有iT2I提示的模型。结果如表1所示，可以观察到iT2I提示只带来轻微的降级。
<img src="/p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-6.png"
	width="407"
	height="261"
	srcset="/p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-6_hu0f7e928cf01e99b3e04bfddf5f0de5d6_65292_480x0_resize_box_3.png 480w, /p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-6_hu0f7e928cf01e99b3e04bfddf5f0de5d6_65292_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="Alt text"
	
	
		class="gallery-image" 
		data-flex-grow="155"
		data-flex-basis="374px"
	
></p>
<p><strong>不同大语言模型的比较</strong></p>
<p><img src="/p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-7.png"
	width="1902"
	height="1154"
	srcset="/p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-7_huc82d7b839fc53b7a5c86bd3cdfedcac6_1424439_480x0_resize_box_3.png 480w, /p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-7_huc82d7b839fc53b7a5c86bd3cdfedcac6_1424439_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="Alt text"
	
	
		class="gallery-image" 
		data-flex-grow="164"
		data-flex-basis="395px"
	
></p>
<p><img src="/p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-8.png"
	width="1902"
	height="1154"
	srcset="/p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-8_huc82d7b839fc53b7a5c86bd3cdfedcac6_1424439_480x0_resize_box_3.png 480w, /p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-8_huc82d7b839fc53b7a5c86bd3cdfedcac6_1424439_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="Alt text"
	
	
		class="gallery-image" 
		data-flex-grow="164"
		data-flex-basis="395px"
	
></p>
<p><strong>iT2I Examples</strong></p>
<p><img src="/p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-9.png"
	width="1902"
	height="1154"
	srcset="/p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-9_huc82d7b839fc53b7a5c86bd3cdfedcac6_1424439_480x0_resize_box_3.png 480w, /p/mini-dalle-3-%E9%80%9A%E8%BF%87%E6%8F%90%E7%A4%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/image-9_huc82d7b839fc53b7a5c86bd3cdfedcac6_1424439_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="Alt text"
	
	
		class="gallery-image" 
		data-flex-grow="164"
		data-flex-basis="395px"
	
></p>
<p>设计的logo还挺有那味儿的</p>

</section>


    <footer class="article-footer">
    
    <section class="article-tags">
        
            <a href="/tags/%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%96%87%E7%94%9F%E5%9B%BE/">交互式文生图</a>
        
    </section>


    
    <section class="article-copyright">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <path d="M14.5 9a3.5 4 0 1 0 0 6" />
</svg>



        <span>Licensed under CC BY-NC-SA 4.0</span>
    </section>
    <section class="article-lastmod">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



        <span>
            Last updated on Aug 20, 2024 22:34 &#43;0800
        </span>
    </section></footer>


    
        <link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI&#43;WdtXRGWt2kTvGFasHpSy3SV"crossorigin="anonymous"
            ><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG&#43;vnGctmUb0ZY0l8"crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"integrity="sha384-&#43;VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4&#43;/RRE05"crossorigin="anonymous"
                defer
                >
            </script><script>
    window.addEventListener("DOMContentLoaded", () => {
        renderMathInElement(document.body, {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
                { left: "\\[", right: "\\]", display: true }
            ],
            ignoredClasses: ["gist"]
        });})
</script>
    
</article>

    

    

<aside class="related-content--wrapper">
    <h2 class="section-title">Related content</h2>
    <div class="related-content">
        <div class="flex article-list--tile">
            
                
<article class="has-image">
    <a href="/p/lumina-mgpt-%E5%85%A8%E8%83%BD%E7%9A%84%E9%AB%98%E8%B4%A8%E9%87%8F%E6%96%87%E7%94%9F%E5%9B%BE%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B/">
        
        
            <div class="article-image">
                <img src="/p/lumina-mgpt-%E5%85%A8%E8%83%BD%E7%9A%84%E9%AB%98%E8%B4%A8%E9%87%8F%E6%96%87%E7%94%9F%E5%9B%BE%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B/image-2.ab9c2f234d49c0d20ab058688a9ac36a_hu0f7e928cf01e99b3e04bfddf5f0de5d6_318245_250x150_fill_box_smart1_3.png" 
                        width="250" 
                        height="150" 
                        loading="lazy"
                        alt="Featured image of post Lumina-mGPT: 全能的高质量文生图多模态大模型"
                        
                        data-hash="md5-q5wvI01JwNIKsFhoiprDag==">
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">Lumina-mGPT: 全能的高质量文生图多模态大模型</h2>
        </div>
    </a>
</article>

            
                
<article class="has-image">
    <a href="/p/all-papers-about-diffusion-models-on-arxiv/">
        
        
            <div class="article-image">
                <img src="/p/all-papers-about-diffusion-models-on-arxiv/_hu97d061de95afac90ca03bfd8d919a16b_239242_538f2624a81473eb1fd40013472e5733.jpeg" 
                        width="250" 
                        height="150" 
                        loading="lazy"
                        alt="Featured image of post All papers about diffusion models on arxiv"
                        
                        data-hash="md5-ho7mJyGJc4P2VN3XPYZazA==">
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">All papers about diffusion models on arxiv</h2>
        </div>
    </a>
</article>

            
                
<article class="has-image">
    <a href="/p/storydiffusion%E8%AE%A9-diffusion-%E7%94%A8%E6%9D%A5%E7%94%9F%E6%88%90%E6%95%85%E4%BA%8B%E6%8F%92%E7%94%BB%E5%92%8C%E8%A7%86%E9%A2%91/">
        
        
            <div class="article-image">
                <img src="/p/storydiffusion%E8%AE%A9-diffusion-%E7%94%A8%E6%9D%A5%E7%94%9F%E6%88%90%E6%95%85%E4%BA%8B%E6%8F%92%E7%94%BB%E5%92%8C%E8%A7%86%E9%A2%91/assets/index/image.1fa74d1073fae62cdc25d8c51b2d6cda_hu5d9292eb672e6ca5e72e74d52b3afcdc_3182605_250x150_fill_box_smart1_3.png" 
                        width="250" 
                        height="150" 
                        loading="lazy"
                        alt="Featured image of post StoryDiffusion：让 Diffusion 用来生成故事插画和视频"
                        
                        data-hash="md5-H6dNEHP65izcJdjFGy1s2g==">
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">StoryDiffusion：让 Diffusion 用来生成故事插画和视频</h2>
        </div>
    </a>
</article>

            
                
<article class="has-image">
    <a href="/p/cross-attention-makes-inference-cumbersome-in-text-to-image-diffusion-models/">
        
        
            <div class="article-image">
                
                    <img src="https://raw.githubusercontent.com/Tlooh/blog-imgs/main/web/202405061001750.png" loading="lazy" data-key="" data-hash="https://raw.githubusercontent.com/Tlooh/blog-imgs/main/web/202405061001750.png"/>
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">Cross-Attention Makes Inference Cumbersome in Text-to-Image Diffusion Models</h2>
        </div>
    </a>
</article>

            
                
<article class="has-image">
    <a href="/p/sdxs-real-time-one-step-latent-diffusion-models-with-image-conditions/">
        
        
            <div class="article-image">
                
                    <img src="https://raw.githubusercontent.com/Tlooh/blog-imgs/main/web/202404281401795.png" loading="lazy" data-key="" data-hash="https://raw.githubusercontent.com/Tlooh/blog-imgs/main/web/202404281401795.png"/>
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">SDXS: Real-Time One-Step Latent Diffusion Models with Image Conditions</h2>
        </div>
    </a>
</article>

            
        </div>
    </div>
</aside>

     
    
        
    <div class="disqus-container">
    <div id="disqus_thread"></div>
<script>
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "hugo-theme-stack" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>

<style>
    .disqus-container {
        background-color: var(--card-background);
        border-radius: var(--card-border-radius);
        box-shadow: var(--shadow-l1);
        padding: var(--card-padding);
    }
</style>

<script>
    window.addEventListener('onColorSchemeChange', (e) => {
        if (typeof DISQUS == 'object') {
            DISQUS.reset({
                reload: true
            });
        }
    })
</script>

    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2020 - 
        
        2024 Tlooh
    </section>
    
    <section class="powerby">
        Built with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> <br />
        Theme <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.26.0">Stack</a></b> designed by <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a>
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
